%! Author = kulagins
%! Date = 02.05.24

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}

% Document
\begin{document}

    \paragraph{Workflow-related changes}

    \begin{itemize}
        \item A task $v$ takes longer or shorter to execute than planned: its time weight $w_u$ changes to $w'_u$.
        \item A task $v$ takes more or less memory to execute than planned: its memory requirement $m_v$ changes to $m'_v$.

    \end{itemize}

    The following changes are not a part of this article's scope:

    \begin{itemize}
        \item The workflow structure changes: edges or tasks come in or leave.
    \end{itemize}

    \paragraph{Execution environment-related changes }


    \begin{itemize}
        \item A processor exists the execution environment: $k$ decreases and $\cluster$ changes.
        \item A processor enters the execution environment: $k$ increases, $\cluster$ gets a new processor with possibly new memory requirement and processor speed.

    \end{itemize}

    The following changes are not a part of this article's scope:

    \begin{itemize}
        \item Processor characteristics change: the memory requirement or speed become bigger or smaller
    \end{itemize}

    \subsection{Time of changes }

    We consider discrete time in seconds.
    The time point(s) at which the changes happen is unambiguously defined.

    For any task $v$, its runtime equals its time weight divided by the speed of the processor $p_j$ it has been assigned to: $w_v/s_j$.
    The start time of any task $v$ is its top level($\bar{l}_v$), or the difference between the maximum bottom level in the workflow (the makespan of the workflow) and the task's own bottom level: $\bar{l}_v = \mu_\Gamma - \bottomlevel{v}$.
    The start time of the source task in the workflow is zero.
    The end time of a task $v$ is its start time and its runtime: $\bar{l}_v + w_v/s_j$

    \subsection{Changes and knowledge horizon - important questions TBA}

    Given a valid mapping of tasks to processors, we can say what we predicted would happen at any given time point $T$: what tasks have been executed, what have not finished or have not even started.

    At the point of change, we know that some tasks that finished took longer than expected ($w_v$ are bigger) or shorter.
    However, how do we model the following:
    \begin{itemize}
        \item Do we know the new weights of currently running tasks and tasks that have not yet started? This means, do we foresee into the future or do we assume that all weights on unfinished tasks remain the same?
        \item A change in memory requirements can mean that the assignment had been invalid. Do we assume that these tasks failed and we need to rerun them?
        \item How many times of change do we model - one per workflow run, or multiple?
        \item At what time does the change and reevaluation happen - is it a fixed (random?) point of time or is it workflow-dependent (say, after 10\% of the workflow is ready)?
    \end{itemize}


    \subsection{Dynamic Scenario}

    In a workflow execution environment, the scheduling method interacts with the runtime environment, which provides information such as resource estimates.
    This information may include, memory usage, runtime, graph structures, or the status of the underlying infrastructure.
    In order to ensure that the information is up to date, a monitoring system observes the workflow execution and collects metrics for tasks and the underlying infrastructure.
    By incorporating dynamic monitoring values, e.g., the resources a task consumed, the runtime environment can incorporate the data into the prediction model to provide more accurate resource predictions.
    Also the underlying infrastructure can change during the workflow execution.
    Examples are processor failures, node recoveries, or acquisition of new nodes.
    However, also when the hardware of the infrastructure does not change, the set of nodes provided as a scheduling target might change due to release or occupation in shared cluster infrastructures.
    As infrastructure information and resource predictions are dynamically updated and provided to the scheduler during the workflow runtime, the previous schedule becomes invalid and a new one must be calculated.

    For state-of-the-art memory prediction methods, a cold-start median prediction error for heterogeneous infrastructures of approximately 15\% is shown~\cite{}.
    Online prediction methods were able to significantly reduce the error during runtime, with the reduction reaching up to one-third of the cold-start error~\cite{baderDiedrichDynamic2023,witt2019learning}.
%For instance, Nadeen~et~al.\cite{} report an error of 10\%, 11\%, and 15\% while the task prediction errors shows a normal and exponential distribution.
%Bader~et~al.~ report a prediction error between 13\% and 17\% for their method, showing an exponential task error distribution.
% @Svetlana, willst du sowas f√ºr deine Experimente? Also die Daten, welche du dann konfigurieren kannst?
    Such a dynamic execution environment necessitates for a dynamic scheduling method where the schedule can be recomputed during the workflow execution.

    \subsection{Retracing the effects of change on an existing schedule}
    After the monitoring system has reported changes, we need to assess their impact on the existing schedule.
    These changes can invalidate the schedule (\eg if there is not enough memory for some tasks to execute anymore),
    they can lead to a later finishing time (\eg if some tasks longer and delay other tasks), or they can have no effect (\eg if new processors
    joined the cluster, but the old schedule did not account for them).
    To assess the impact, we need to retrace the schedule.

    First, we find out if at least one processor that had assigned tasks has exited - this instantly invalidates the
    entire schedule.

    We then iterate over all tasks of the workflow in a topological order - any of the orderings given by rankings BL, BLC or MM
    is a topologial ordering.
    We then repeat steps similar to those we did during tentative assignment in our heuristic, except we do not choose a processor
    anymore, but rather see if the current one still fits.

    For each task $v$, we first assess its current memory constraint $Res$ using Step 2 from our heuristic.
    The factors that affect $Res$ are possible changes in $m_v$, in $c_{u,v}$ from predecessors $u$ or $c_{v,w}$ from successors $w$,
    available memory $availM_j$ on the processor (due to either changed $M_j$ or changed memory requirements from other tasks).
    If originally,$Res$ was positive (no files were evicted from memory into the communication buffer), then it has to stay this way -
    otherwise evicted files can invalidate next tasks.
    If original $Res$ was negative, then we need to make sure that evicted files still fit into the communication buffer.
    If either $Res$ is newly negative, or the communication buffer is not large enough, this invalidates the schedule.
    We update the $availM_j$ and $availMC_j$ according to the new memory constraints.

    Then we can re-calculate the finish time of the task on its processor like in Step 3.
    The factors that affect it are changes in own execution time $w_v$ of the tasks, changed ready time of the processor
    (after delayed previous tasks), and changed communication buffer availability.

    Then, after having updated the processor's values, we move on to the next task.

    \section{Related work}
    \skug{problem: this is written for the old heuristic - parititioning-based heuristic to solvea dynamic problem! it is irrelevant to heft}

    In the limited time I spent looking, I found no paper addressing the exact same problem.

    Wang et al.~\cite{wang2019dynamic} proposes a dynamic particle swarm optimization algorithm to schedule workflows in a cloud.
    Particles are possible solution in the solution space.
    However, the dynamic is only in the choice of generation sizes, not in the changes in the execution environment.
    Singh et al.~\cite{singh2018novel} addresses dynamic provisioning of resources with a constraint deadline.
    However, the approach is for clouds.
    \xspace

    Daniels et al.~\cite{daniels1995robust} formalize the concept of robust scheduling with variable processing times
    on a single machine.
    The changes in runtimes of tasks are not due to changing machine properties, but are rather task-related (that means
    that these runtime changes are unrelated to each other).
    The authors formulate a decision space of all permutations of n jobs, and the optimal schedule in relation to a
    performance measure $\phi$.
    Then they proceed to formulate the Absolute Deviation Robust Scheduling Problem as a set of linear constraints.

    De Olivera~\etal~\cite{de2012provenance} propose a tri-criteria (makespan, reliability, cost) adaptive scheduling heuristic
    for clouds.
    Based on a 3-objective cost model, their greedy scheduling algorithm schedules tasks into machines.
    The authors use provenance data to make scheduling decisions.
    The cost model is a set of linear equations computed in the simulation environment, it represents the cost of an execution based on the criteria.
    In the algorithms, the authors test out 4 scenarios - one preferring each criteria, and a balanced one.
    The algorithm merely chooses the best virtual machine for each next task based on the cost given by the model.
    An additional algorithm combines several cloud activities (task executions) into one to improve the cost, so that each
    execution is not too small (utilize the granularity factor, the smallest entity of payment of the cloud producer).
    The authors used workflows with less than 10 tasks, but repeated them so that the execution had up to 200 tasks.
    They do not report the runtime of the scheduling algorithm, only the speedup and cost saving it produces.

    Rahman~\etal~\cite{rahman2013} propose a scheduling heuristic for grids that proposes mapping of tasks to machines by calculating
    the critical path in the graph dynamically at every step.
    They call it the dynamic critical path (DCP).
    For all tasks they compute the earliest start time and absolute latest start time that are upper and lower bounds
    on the start time of a task (differing by the slack this task has).
    All tasks on this critical path have the same earliest and latest start times, because they cannot be ddelayed.

    The algorithm takes the first unscheduled task on the critical path each time and maps it on a processor identified for it.
    If processors are heterogeneous, then the start times are computed with respect for the processor, and the minimum execution time for
    the task is chosen.
    The heuristic also uses the same processor to schedule parent and children tasks, as to avoid data transfer between processors.
    The authors evaluate their approaches on random workflows of the size up to 300 tasks.

    The authors provide an overview over (simpler) scheduling heuristics.
    For example, GRASP (generally randomized adaptive search procedure) conducts a number of iterations to search an optimal
    solution for mapping tasks on machines.
    A solution is generated at each step, and the best solution is kept at the end.
    The search terminates when a certain termination criterion is reached.
    It generates better results than other algorithms, because it explores the whole solution space.

    Avanes~\etal\cite{avanes2008adaptive} present a heuristic for networks in disaster scenarios.
    These networks are a set of DAG-shaped scenarios, out of which one needs to be executed.
    The scenario contains AND- and OR-branches, where AND-branches indicate acitivities that need to be executed in parallel.

    The heuristic first partitions the set into local schedules by using affinity matrices to determine similar
    activities and group them together.
    Then they physically allocate these partitions to groups of disaster responders and tasks within this group.
    They define a constraint system for that.
    The dynamic part deals with changes and distinguishes between retriable and compensation acitivities.
    The heuristic calculates a new execution path with these tasks.
    In general, this heuristic is not as related as it looks, because of very specific workflow and task structure.

    Garg~\etal~\cite{GARG2015256} propose a dynamic scheduling algorithm for heterogeneous grids based on rescheduling.
    The aim is to minimize the makespan, and the experiments were conducted on a single wotkflow with 10 tasks.
    The procesdure involves building a first (static) schedule, priodic resource monitoring and rescheduling the remaining
    tasks.
    The resource model contains resource groups (small tightly-connected sub-clusters), connected between each other.
    For each resuorce group, there is an own scheduler, and an overall global scheduler responsible for distributing
    tasks to groups.
    The authors define the execution time, estimated start time, data ready time,a dn estimated finish time per task.
    The runtimes of tasks depend on processor speeds, are calculated in advance and stored in tables.

    The algorithm first computes bottom levels for all tasks (execution time is average of all possible execution times).
    THe bottom level represents the priority of the task, and tasks are sorted according to these priorities.
    They then go through tasks and map than to such processors that minimize the earliest start times of this task's
    successors.
    To do this, the authors calculate the earliest finishing time of the task across all ressources, along with the
    average communication and computation costs fir the dependent tasks.

    The rescheduling is being triggered when either a load on a resource increases over a threshold, or if a new resource
    is added.
    The algorithm produces a new mapping from scrath, and this mapping is being accepted if the resulting maespan is
    smaller than the previously predicted one.
\end{document}